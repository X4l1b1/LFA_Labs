{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Testing and comparaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import _tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from FCM_SS_2 import FCM_SS_2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "DATASETS_PATHS = ['datasets/melanomaTest.dat.csv', 'datasets/seeds_dataset.csv'] # http://cibcb.org/data/\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename):\n",
    "    dataset = np.genfromtxt(filename, delimiter=';')\n",
    "    \n",
    "    # save all the labels to calculate the performance of our algorithm\n",
    "    true_labels = copy.copy(dataset[:, -1])\n",
    "    labels_names = np.unique(true_labels)\n",
    "    \n",
    "    return dataset, true_labels, labels_names\n",
    "\n",
    "DATASETS = []\n",
    "for path in DATASETS_PATHS:\n",
    "    DATASETS.append(loadDataset(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove some labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLabels(dataset, labels_name, percentage):  \n",
    "    result = copy.copy(dataset)\n",
    "    # remove percentage of each different labels for test purpose       \n",
    "    for label in labels_name:\n",
    "        subArrayIdx = np.where(result[:,-1] == label)[0]\n",
    "        idx = np.random.choice(subArrayIdx, int(len(subArrayIdx)*percentage/100), replace=False)\n",
    "        for i in idx:\n",
    "            result[i][-1] = 0\n",
    "            \n",
    "\n",
    "    return result\n",
    "#for dataset in DATASETS:\n",
    "#    dataset[0] = removeLabels(dataset[0], dataset[2], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5d0d3aa51282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFCM_SS_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuzzy_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembership_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LFA/LFA_Labs/LFA Project/FCM_SS_2.py\u001b[0m in \u001b[0;36mclusterize\u001b[0;34m(self, dataset, labels_names)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LFA/LFA_Labs/LFA Project/FCM_SS_2.py\u001b[0m in \u001b[0;36mgetClass\u001b[0;34m(self, dataset, labels, k, labels_names)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mcount_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "fcm = FCM_SS_2() \n",
    "fcm.setParams(fuzzy_param=2, membership_threshold=0.95)\n",
    "labels, centers, mb = fcm.clusterize(DATASETS[1][0], DATASETS[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(labels, DATASETS[1][1])\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(DATASETS[1][2]))\n",
    "    plt.xticks(tick_marks, DATASETS[1][2], rotation=45)\n",
    "    plt.yticks(tick_marks, DATASETS[1][2])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "plot_confusion_matrix(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(labels, DATASETS[1][1]))\n",
    "precision = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[1][0]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[0][1]))/2\n",
    "print(\"Precision: \", precision)\n",
    "recall = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[0][1]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[1][0]))/2\n",
    "print(\"Recall: \", recall)\n",
    "f1score = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F1-Score: \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = DATASETS[1][0]\n",
    "true_labels = DATASETS[1][1]\n",
    "labels_names = DATASETS[1][2]\n",
    "print(len(true_labels))\n",
    "print(len(labels))\n",
    "fuzzy_params = np.arange(1,5,0.1)\n",
    "mb_threshold_values = np.arange(0.8,1.05,0.05)\n",
    "\n",
    "def computeClustering(fuzzy_param, mb_threshold_value):\n",
    "    fcm.setParams(fuzzy_param=fuzzy_param, membership_threshold=mb_threshold_value)\n",
    "    labels, centers, mb = fcm.clusterize(dataset, labels_names)\n",
    "    return accuracy_score(labels, true_labels)\n",
    "\n",
    "print(computeClustering(2, 0.95))\n",
    "fig = plt.figure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "fuzzy_params, mb_threshold_values = np.meshgrid(fuzzy_params, mb_threshold_values)\n",
    "\n",
    "accurencies = np.array([computeClustering(x,y) for x,y in zip(np.ravel(fuzzy_params), np.ravel(mb_threshold_values))])\n",
    "accurencies = accurencies.reshape(mb_threshold_values.shape)\n",
    "\n",
    "graph = ax.plot_surface(fuzzy_params, mb_threshold_values, accurencies, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlabel('Fuzzy param')\n",
    "ax.set_ylabel('Membership threshold')\n",
    "ax.set_zlabel('Accuracy')\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(0, 1.00)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(graph, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def computeClustering(percentageOmission):\n",
    "    dataset = DATASETS[1][0]\n",
    "    true_labels = DATASETS[1][1]\n",
    "    labels_names = DATASETS[1][2]\n",
    "    dataset = removeLabels(dataset, labels_names, percentageOmission) \n",
    "    fcm.setParams(fuzzy_param=2, membership_threshold=0.975)\n",
    "    labels, centers, mb = fcm.clusterize(dataset, labels_names)\n",
    "    return accuracy_score(labels, true_labels)\n",
    "\n",
    "labelOmission = np.arange(0, 100)\n",
    "accurencies = np.array([computeClustering(x) for x in labelOmission])\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.plot(labelOmission, accurencies, 'r')\n",
    "axes.set_xlabel('Percentage of Unlabeled Data')\n",
    "axes.set_ylabel('Accurency')\n",
    "axes.set_title('Evolution of the FCM accurency depending on the percentage of labelised data');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
